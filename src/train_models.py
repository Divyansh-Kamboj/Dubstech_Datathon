"""
Project Aesclepius â€” ML Model Training
=======================================
Trains two models on the NY SPARCS 2022 inpatient dataset:

  A.  **XGBoost Classifier** â€” predicts APR Risk-of-Mortality level (0-3).
  B.  **Cox Proportional-Hazards** â€” predicts survival curves using
      Length of Stay as the duration and patient expiry as the event.

Artefacts are saved under ``models/``.
"""

import os
import pickle

import numpy as np
import pandas as pd
import xgboost as xgb
from lifelines import CoxPHFitter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Paths & constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_PATH = os.path.join(ROOT_DIR, "sparcs_2022.csv")
MODELS_DIR = os.path.join(ROOT_DIR, "models")

# APR MDC Codes â†’ our 4 departments
DEPT_MAP = {
    5:  "Cardiology",
    17: "Oncology",
    10: "Endocrinology",
    19: "Mental Health",
}

# Mortality-string â†’ integer encoding
MORTALITY_MAP = {
    "Minor":    0,
    "Moderate":  1,
    "Major":     2,
    "Extreme":   3,
}

# Age-group â†’ ordinal encoding
AGE_MAP = {
    "0 to 17":     0,
    "18 to 29":    1,
    "30 to 49":    2,
    "50 to 69":    3,
    "70 or Older":  4,
}


def main() -> None:
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. Safety: create models/ directory
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    os.makedirs(MODELS_DIR, exist_ok=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. Load data (cap at 500 000 rows for memory safety)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ“‚  Loading SPARCS 2022 data â€¦")
    df = pd.read_csv(DATA_PATH, low_memory=False, nrows=500_000)
    print(f"   Raw shape: {df.shape}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. Filter for our 4 departments
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df["APR MDC Code"] = pd.to_numeric(df["APR MDC Code"], errors="coerce")
    df = df[df["APR MDC Code"].isin(DEPT_MAP.keys())].copy()
    df["Department"] = df["APR MDC Code"].map(DEPT_MAP)
    print(f"   After department filter: {df.shape}")
    print(f"   Department distribution:\n{df['Department'].value_counts().to_string()}\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. Drop rows with missing targets
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df = df.dropna(subset=["APR Risk of Mortality", "Length of Stay"])
    print(f"   After dropping NaNs: {df.shape}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 6. Preprocessing
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # Target A â€” Mortality level (ordinal 0-3)
    df["Mortality_Level"] = df["APR Risk of Mortality"].map(MORTALITY_MAP)
    df = df.dropna(subset=["Mortality_Level"])          # drop unmapped values
    df["Mortality_Level"] = df["Mortality_Level"].astype(int)

    # Target B â€” Event column for Cox model
    df["Event"] = (df["Patient Disposition"] == "Expired").astype(int)

    # Length of Stay â†’ numeric (some SPARCS files encode 120+ as a string)
    df["Length of Stay"] = pd.to_numeric(
        df["Length of Stay"].astype(str).str.replace("+", "", regex=False),
        errors="coerce",
    )
    df = df.dropna(subset=["Length of Stay"])
    df["Length of Stay"] = df["Length of Stay"].astype(float)
    # Cox requires durations > 0
    df["Length of Stay"] = df["Length of Stay"].clip(lower=0.5)

    # Feature: Age_Numeric
    df["Age_Numeric"] = df["Age Group"].map(AGE_MAP).fillna(-1).astype(int)

    # Feature: Emergency_Flag
    df["Emergency_Flag"] = (df["Emergency Department Indicator"] == "Y").astype(int)

    # Feature: Dept_Code (label-encoded 0-3)
    dept_le = LabelEncoder()
    df["Dept_Code"] = dept_le.fit_transform(df["Department"])

    print(f"   Final training set: {df.shape}")
    print(f"   Mortality_Level distribution:\n{df['Mortality_Level'].value_counts().sort_index().to_string()}")
    print(f"   Event (Expired) distribution:\n{df['Event'].value_counts().to_string()}\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 7. Define feature matrix
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    FEATURES = ["Age_Numeric", "Emergency_Flag", "Dept_Code"]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 8. Model A â€” XGBoost Classifier
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸŒ²  Training XGBoost classifier â€¦")
    X = df[FEATURES].values
    y = df["Mortality_Level"].values

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y,
    )

    xgb_model = xgb.XGBClassifier(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        objective="multi:softmax",
        num_class=4,
        eval_metric="mlogloss",
        use_label_encoder=False,
        random_state=42,
    )
    xgb_model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=50,
    )

    y_pred = xgb_model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n   XGBoost accuracy: {acc:.4f}")
    print(classification_report(
        y_test, y_pred,
        target_names=["Minor", "Moderate", "Major", "Extreme"],
    ))

    xgb_path = os.path.join(MODELS_DIR, "xgb_mortality.json")
    xgb_model.save_model(xgb_path)
    print(f"   âœ… Saved XGBoost model â†’ {xgb_path}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 9. Model B â€” Department-Stratified Cox Proportional-Hazards
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“ˆ  Training per-department Cox Proportional-Hazards models â€¦")
    cox_cols = ["Age_Numeric", "Emergency_Flag", "Length of Stay", "Event"]
    cox_models = {}  # {dept_name: fitted CoxPHFitter}

    for code, dept_name in DEPT_MAP.items():
        df_dept = df[df["APR MDC Code"] == code][cox_cols].copy()
        if df_dept.empty or df_dept["Event"].sum() == 0:
            print(f"   âš ï¸  {dept_name}: skipped (no events or no data)")
            continue

        print(f"\n   â”€â”€ {dept_name} (n={len(df_dept):,}, events={int(df_dept['Event'].sum()):,}) â”€â”€")
        cph = CoxPHFitter()
        cph.fit(df_dept, duration_col="Length of Stay", event_col="Event")
        cph.print_summary()
        cox_models[dept_name] = cph

    # Save the dict of all per-department Cox models
    cox_dict_path = os.path.join(MODELS_DIR, "cox_models.pkl")
    with open(cox_dict_path, "wb") as f:
        pickle.dump(cox_models, f)
    print(f"\n   âœ… Saved {len(cox_models)} Cox models â†’ {cox_dict_path}")

    # Also keep a legacy single-file for backward compat (first model)
    if cox_models:
        legacy_path = os.path.join(MODELS_DIR, "cox_survival.pkl")
        with open(legacy_path, "wb") as f:
            pickle.dump(next(iter(cox_models.values())), f)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 10. Save configuration / mappings for the app
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    config = {
        "mortality_map":     MORTALITY_MAP,
        "inv_mortality_map": {v: k for k, v in MORTALITY_MAP.items()},
        "age_map":           AGE_MAP,
        "dept_map":          DEPT_MAP,
        "dept_label_encoder": dept_le,
        "features":          FEATURES,
    }
    config_path = os.path.join(MODELS_DIR, "config.pkl")
    with open(config_path, "wb") as f:
        pickle.dump(config, f)
    print(f"   âœ… Saved config mappings â†’ {config_path}")

    print("\nğŸ‰  All models trained and saved successfully!")


if __name__ == "__main__":
    main()
